### الگوریتم Sliding Window Log ـ <Note>با نام Sliding Log هم شناخته می‌شود</Note>

این الگوریتم با ذخیره کردن timestamp هر درخواست کار می‌کنه.
وقتی یک درخواست جدید دریافت می‌کنیم:
- ابتدا تمام timestamp های قدیمی شده رو پاک می‌کنیم.
- درخواست جدید رو رکورد می‌کنیم
- در نهایت با چک کردن اندازه رکورد هامون، تصمیم میگیریم که request رو بلاک کنیم یا نه.

بیایم اینو با مثالی که
[بالا](#anchor-ratelimit-example)
زدیم، باز کنیم:

![sliding window log diagram 1](ratelimit_sliding_window_log_1.png)

در ابتدا ۵ درخواست داریم که هر کدوم با فاصله های زمانی یک ثانیه‌ای به سمت ما ارسال میشن.
چون از قبل رکوردی نداریم و زمان ها در بازه
threshold
هستند(جلوتر میفهمیم این چیه)
هیچکدوم پاک نمیشن و همشون ثبت میشن. لاگمون الان اندازش ۵ هست و
چون بزرگتر از rate امون نیست،
لازم نیست آخرین درخواست رو بلاک کنیم. میریم جلوتر:

![sliding window log diagram 2](ratelimit_sliding_window_log_2.png)

یک ثانیه بعد یک درخواست جدید میاد، همه رکورد های قبلی توی بازه زمانیمون قرار دارن
(نقطه چین)
در نتیجه هیچ رکوردی حذف نمیشه. درخواست فعلی رو رکورد می‌کنیم. چون اندازه
لاگمون بیشتر از ۵ شد، باید درخواست رو بلاک کنیم.

> بازه زمانی توی sliding window log میشه بازه درخواست فعلی تا t ثانیه<Note>یا هر واحد زمان دیگه</Note> قبل.

بریم جلوتر:

![sliding window log diagram 3](ratelimit_sliding_window_log_3.png)

۲ ثانیه بعد، یک درخواست جدید میاد.
چون رکورد های ۱ و ۲ خارج از بازه زمان هستن، اونارو از لاگمون پاک می‌کنیم،
بعد درخواست فعلی رو رکورد می‌کنیم. چون اندازه لاگمون بیشتر از ۵ نیست،
لازم نیست درخواست رو بلاک کنیم. این الگوریتم به همین ترتیب برای درخواست بعدی
عمل می‌کنه.

<br/>

یکی از خوبی های این الگوریتم، تعریف متفاوت اون از بازه نسبت به
الگوریتم fixed window هست.
بازه ها توی
fixed window
ثابت اما اینجا پویاست. در نتیجه این الگوریتم گارانتی می‌کنه که درخواست هایی فقط
قبول می‌شن که تعداد درخواست ها
از t ثانیه قبلشون تا به الان
از حد قانون یا rate
بیشتر نباشه.

اما در fixed window این گارانتی وجود نداره در نتیجه اگه قانونی مثل
`rate=1000, t=24hr` داشته باشیم و فرض کنیم
origin همان ابتدای روز است،
اگه کاربر از ۹ تا ۱۰ صبح 1000 درخواست خودش رو مصرف کنه، دیگه اجازه نداره تا روز بعدی درخواست جدیدی بفرسته.
اما توی sliding window اینطور نیست و بعد از ظهر می‌تونه
مجدد درخواست ارسال کنه. نه
1000 تا
،‌ کمتر ولی دسترسیش کامل از سایت قطع نمیشه.<Note>این می‌تونه هم خوب باشه هم بد ولی اکثر استفاده کنندگان ratelimit، این مدل رو بیشتر ترجیح میدن.</Note>
بجاش صبح روز بعد کمتر از 1000 تا درخواست می‌تونه ارسال کنه.
<br />

این الگوریتم بدی هم داره، مموری زیادی نسبت به الگوریتم های دیگه مصرف می‌کنه و تحت کنترلمون نیست.
توی fixed window
ما می‌دونیم که هر کاربر یک اندازه ثابت مموری نیاز داره و بیشتر نمیشه
(مثلا ۱۲۸ بایت ثابت)
اما توی sliding window log
چون ما باید لیستی از لاگ ها رو برای هر کاربر ذخیره کنیم، دقیقا نمی‌دونیم که هر کاربر چقدر مموری نیاز داره.
مثلا یک کاربر میتونه نسبت به درخواست هایی که میده ۱۰ مگابایت مموری مصرف کنه و 
یک کاربر دیگه ۱۰۰ کیلوبایت.

مشکل دیگه‌ای هم که داره اگه از یک کاربر ۵ مگابایت رکورد داشته باشیم و این کاربر هیچوقت دیگه
به سایتمون سر نزنه، هیچ وقت رکورد های قدیمی رو پاک نمی‌کنیم و این ۵ مگ رو الکی نگه داشتیم و از منابع به خوبی استفاده نکردیم.
در نتیجه باید یک فرایند پس‌زمینه‌ای داشته باشیم که هرچند وقت یکبار همه رکورد ها برای همه کاربر هارو
بررسی کنه و رکورد های قدیمی رو پاک کنه. اگه این کار رو هم انجام بدیم مشکلات همزمانی
خودشون رو نشون میدن که اگه اونارو هم با لاک کردن حل کنیم، روی پرفرمنس تاثیر زیادی میزارن
که برای سیستمی که بار سنگینی رو پردازش میکنه
(مثل CDN)
اصلا ایده‌آل نیست. جلوتر توی این نوشته بیشتر در این مورد صحبت می‌شه.

نمونه پیاده سازی این الگوریتم در زبان Rust:

```rust
// <hide>
use std::time::{Duration, SystemTime, UNIX_EPOCH};
// </hide>

struct Rule {
    time_duration: Duration,
    rate: usize,
}

type Log = Vec<u128>;

fn is_rate_limited(current_time: SystemTime, rule: &Rule, log: &mut Log) -> bool {
    let current_timestamp = current_time.duration_since(UNIX_EPOCH).unwrap().as_millis();
    let time_duration_ms = rule.time_duration.as_millis();
    // cleanup
    let mut logs_to_pop = 0;
    for timestamp in log.iter() {
        if *timestamp < current_timestamp - time_duration_ms {
            logs_to_pop += 1;
        }
    }
    log.drain(0..logs_to_pop);
    if log.len() >= rule.rate {
        true
    } else {
        // append
        log.push(current_timestamp);
        false
    }
}

// <hide>
fn main() {
    let rule = &Rule {
        time_duration: Duration::from_secs(5),
        rate: 5,
    };
    let mut current_time = SystemTime::now();
    let state = &mut Vec::new();

    for _ in 1..=5 {
        assert_eq!(is_rate_limited(current_time, rule, state), false);
        current_time += Duration::from_secs(1);
    }
    assert_eq!(is_rate_limited(current_time, rule, state), true);
    current_time += Duration::from_secs(2);
    assert_eq!(is_rate_limited(current_time, rule, state), false);
    assert_eq!(is_rate_limited(current_time, rule, state), false);
    assert_eq!(is_rate_limited(current_time, rule, state), true);
}
// </hide>
```